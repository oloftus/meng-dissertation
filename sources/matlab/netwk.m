function [y1] = netwk(x1)
%NET neural network simulation function.
%
% Generated by Neural Network Toolbox function genFunction, 14-Mar-2016 14:49:55.
% 
% [y1] = net(x1) takes these arguments:
%   x = 3xQ matrix, input #1
% and returns:
%   y = 2xQ matrix, output #1
% where Q is the number of samples.

%#ok<*RPMT0>

  % ===== NEURAL NETWORK CONSTANTS =====
  
  % Input 1
  x1_step1_xoffset = [0;0;0];
  x1_step1_gain = [2;2;2];
  x1_step1_ymin = -1;
  
  % Layer 1
  b1 = [-2.6915316091609535754;2.3513361845629856539;-2.701441320971797122;2.4376264659623951836;4.9891291172279199628];
  IW1_1 = [5.4344734181523630667 6.5639040889254403055 -4.4849528377194802786;-5.1743476449986269827 0.070469101489962868157 -4.0150272103459068163;-2.5482689706929568807 7.3884220797392199387 -4.5766976448001184252;2.557292780468904958 -2.7260836636002587774 2.0954521168471456072;1.9356422090817013704 -9.0149763466181838112 8.2020406664296636734];
  
  % Layer 2
  b2 = [-5.3691871768984054114;-3.7961171997862575012;10.243629715970518745;-2.1381428689587846925;2.0667212301942980979];
  LW2_1 = [5.4131300367981021182 0.40779178188934123162 -8.4794688143080616527 -0.4073358023646487247 4.208033906164886595;8.1204011223878183046 -20.569130722285155599 -2.0518121033581517842 -2.2278116319199798845 -1.0706762565092637907;10.782654668714027224 11.992429644505040898 13.166844960019414401 12.501708203059706648 14.354962922143629456;-3.6382619838707443982 -1.4762407784444857572 -12.529712844053349841 7.5003656392655333462 6.476845846831387199;-5.0725911129161875834 -8.7274556457383809516 7.9403113768469939515 6.0873331648422350781 -2.3843844280870416519];
  
  % Layer 3
  b3 = [0.7498367927268677624;-0.19601575681181060418];
  LW3_2 = [-6.3300226234600067698 -1.0560379717221071161 -0.15146781931413946798 -4.7525996370038745553 10.305224123143752024;6.0528252719130231085 1.1998930924386983499 -1.2350613874484246413 4.4584531422572313275 -8.9888257586992743597];
  
  % ===== SIMULATION ========
  
  % Dimensions
  Q = size(x1,2); % samples
  
  % Input 1
  xp1 = mapminmax_apply(x1,x1_step1_gain,x1_step1_xoffset,x1_step1_ymin);
  
  % Layer 1
  a1 = logsig_apply(repmat(b1,1,Q) + IW1_1*xp1);
  
  % Layer 2
  a2 = logsig_apply(repmat(b2,1,Q) + LW2_1*a1);
  
  % Layer 3
  a3 = softmax_apply(repmat(b3,1,Q) + LW3_2*a2);
  
  % Output 1
  y1 = a3;
end

% ===== MODULE FUNCTIONS ========

% Map Minimum and Maximum Input Processing Function
function y = mapminmax_apply(x,settings_gain,settings_xoffset,settings_ymin)
  y = bsxfun(@minus,x,settings_xoffset);
  y = bsxfun(@times,y,settings_gain);
  y = bsxfun(@plus,y,settings_ymin);
end

% Sigmoid Positive Transfer Function
function a = logsig_apply(n)
  a = 1 ./ (1 + exp(-n));
end

% Competitive Soft Transfer Function
function a = softmax_apply(n)
  nmax = max(n,[],1);
  n = bsxfun(@minus,n,nmax);
  numer = exp(n);
  denom = sum(numer,1); 
  denom(denom == 0) = 1;
  a = bsxfun(@rdivide,numer,denom);
end
