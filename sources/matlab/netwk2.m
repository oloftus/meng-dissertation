function [y1] = net(x1)
%NET neural network simulation function.
%
% Generated by Neural Network Toolbox function genFunction, 20-Mar-2016 01:06:07.
% 
% [y1] = net(x1) takes these arguments:
%   x = 3xQ matrix, input #1
% and returns:
%   y = 2xQ matrix, output #1
% where Q is the number of samples.

%#ok<*RPMT0>

  % ===== NEURAL NETWORK CONSTANTS =====
  
  % Layer 1
  b1 = [-0.00092093517454858858651;-10.294702385869646477;-0.93116950045459556673;-3.2266857649334843572;0.019182232085911299357];
  IW1_1 = [3.2763755278984980635 -5.1102435106446755242 -7.3849954238539750051;6.1209839127438030459 3.6515430620181161814 6.5293435645693103098;-7.4016274235091525924 3.3182778678611839496 4.9905516782386536434;-5.5818898295400725118 6.4046266327091716519 -3.8179742958730038538;-9.3808969559370289915 0.39561337312786792886 3.4307815387915114869];
  
  % Layer 2
  b2 = [-6.0130378552536418724;-3.2961560717143121302;-3.7477259086765490892;3.2374420896962012861;-11.516609678668732641];
  LW2_1 = [6.0233512337178236606 0.91096421731877186279 -2.3722592807013973548 3.8354032424806918655 -2.4599641250599422193;2.4693341819887271171 -2.7053693473300333139 -4.0949443798244198334 1.9300717644728655475 5.0751555086104964687;3.5456431321804555701 1.9407614541565283428 0.062831544217157905829 -4.2218833219683684632 4.9979176509801801487;-0.75662919989865262682 0.58717464477603309447 -4.8851180843588695168 -5.371505728715397332 -4.3223867143876466557;-0.5142157697235917313 2.761625729142286545 4.0179806650660907508 0.33643382236648761152 4.6900302053384725909];
  
  % Layer 3
  b3 = [-1.0093840601257275669;0.79641528702958619412];
  LW3_2 = [1.6026950970865647683 0.85780252068647810937 0.51980271986534054562 0.61239761143020376988 4.6949464569809862269;-0.61541924058569841272 0.79769403315274389765 0.035287104163178067973 -1.4071660735479065707 -4.50928058571004442];
  
  % ===== SIMULATION ========
  
  % Dimensions
  Q = size(x1,2); % samples
  
  % Input 1
  % no processing
  
  % Layer 1
  a1 = logsig_apply(repmat(b1,1,Q) + IW1_1*x1);
  
  % Layer 2
  a2 = logsig_apply(repmat(b2,1,Q) + LW2_1*a1);
  
  % Layer 3
  a3 = softmax_apply(repmat(b3,1,Q) + LW3_2*a2);
  
  % Output 1
  y1 = a3;
end

% ===== MODULE FUNCTIONS ========

% Sigmoid Positive Transfer Function
function a = logsig_apply(n)
  a = 1 ./ (1 + exp(-n));
end

% Competitive Soft Transfer Function
function a = softmax_apply(n)
  nmax = max(n,[],1);
  n = bsxfun(@minus,n,nmax);
  numer = exp(n);
  denom = sum(numer,1); 
  denom(denom == 0) = 1;
  a = bsxfun(@rdivide,numer,denom);
end
